{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Training Without Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "import os\n",
    "\n",
    "models_dir = \"models/PPO\"\n",
    "logdir = \"logs\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "env = gym.make('LunarLander-v3')\n",
    "env.reset()\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=logdir)\n",
    "\n",
    "TIMESTEPS = 10000\n",
    "iters = 0\n",
    "for i in range(30):\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=\"PPO\")\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Training with Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 93.8     |\n",
      "|    ep_rew_mean     | -196     |\n",
      "| time/              |          |\n",
      "|    fps             | 3830     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 99           |\n",
      "|    ep_rew_mean          | -173         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2236         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053854156 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.00478      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 422          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 103      |\n",
      "|    ep_rew_mean     | -150     |\n",
      "| time/              |          |\n",
      "|    fps             | 3646     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 24576    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 109         |\n",
      "|    ep_rew_mean          | -134        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2068        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011093883 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 460         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 124      |\n",
      "|    ep_rew_mean     | -99.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 3434     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 138          |\n",
      "|    ep_rew_mean          | -63.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1957         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101880655 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 160      |\n",
      "|    ep_rew_mean     | -48.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 2358     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 57344    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 182         |\n",
      "|    ep_rew_mean          | -40.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1545        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011082364 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.2        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 229      |\n",
      "|    ep_rew_mean     | -29.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 1392     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 286          |\n",
      "|    ep_rew_mean          | -23.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1064         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089972755 |\n",
      "|    clip_fraction        | 0.0786       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.2         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00741     |\n",
      "|    value_loss           | 84           |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 330      |\n",
      "|    ep_rew_mean     | -26.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 1439     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 392        |\n",
      "|    ep_rew_mean          | -20.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1089       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00916278 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.768      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.2       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.00654   |\n",
      "|    value_loss           | 72.3       |\n",
      "----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 446      |\n",
      "|    ep_rew_mean     | -12.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 1096     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 106496   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 515          |\n",
      "|    ep_rew_mean          | -4.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 897          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075943293 |\n",
      "|    clip_fraction        | 0.0846       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 573      |\n",
      "|    ep_rew_mean     | 3.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 1141     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 122880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 629         |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 941         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009237788 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.96       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.84        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 671      |\n",
      "|    ep_rew_mean     | 18.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 1102     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 139264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 720         |\n",
      "|    ep_rew_mean          | 28.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 899         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007255283 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 749      |\n",
      "|    ep_rew_mean     | 36.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 1177     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 792         |\n",
      "|    ep_rew_mean          | 51.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 909         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008061125 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 19.8        |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 827      |\n",
      "|    ep_rew_mean     | 65.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 1194     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 172032   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 861          |\n",
      "|    ep_rew_mean          | 75.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 951          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052761734 |\n",
      "|    clip_fraction        | 0.059        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.863       |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.8          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 20.5         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 866      |\n",
      "|    ep_rew_mean     | 82.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 188416   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 876          |\n",
      "|    ep_rew_mean          | 90.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1006         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058021806 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.814       |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 47.7         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 897      |\n",
      "|    ep_rew_mean     | 96.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 1182     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 868          |\n",
      "|    ep_rew_mean          | 105          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1088         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060714735 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.755       |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 851      |\n",
      "|    ep_rew_mean     | 121      |\n",
      "| time/              |          |\n",
      "|    fps             | 1470     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 221184   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 803        |\n",
      "|    ep_rew_mean          | 128        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1211       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00926282 |\n",
      "|    clip_fraction        | 0.0857     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.764     |\n",
      "|    explained_variance   | 0.697      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 138        |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00428   |\n",
      "|    value_loss           | 74.2       |\n",
      "----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 746      |\n",
      "|    ep_rew_mean     | 136      |\n",
      "| time/              |          |\n",
      "|    fps             | 1423     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 237568   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 671        |\n",
      "|    ep_rew_mean          | 140        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1243       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00634793 |\n",
      "|    clip_fraction        | 0.0767     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.777     |\n",
      "|    explained_variance   | 0.744      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.49       |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.002     |\n",
      "|    value_loss           | 66         |\n",
      "----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 626      |\n",
      "|    ep_rew_mean     | 154      |\n",
      "| time/              |          |\n",
      "|    fps             | 1644     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 253952   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 588          |\n",
      "|    ep_rew_mean          | 159          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1174         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070991945 |\n",
      "|    clip_fraction        | 0.0652       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.749       |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.6         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 55.3         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 548      |\n",
      "|    ep_rew_mean     | 166      |\n",
      "| time/              |          |\n",
      "|    fps             | 1788     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 522         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005665993 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    value_loss           | 97.8        |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | 176      |\n",
      "| time/              |          |\n",
      "|    fps             | 1875     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 286720   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 465          |\n",
      "|    ep_rew_mean          | 182          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1434         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047097337 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.751       |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 83.5         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.000664    |\n",
      "|    value_loss           | 93.9         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 423      |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    fps             | 1812     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 303104   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 422         |\n",
      "|    ep_rew_mean          | 182         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006099418 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 395      |\n",
      "|    ep_rew_mean     | 192      |\n",
      "| time/              |          |\n",
      "|    fps             | 2038     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 319488   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 390          |\n",
      "|    ep_rew_mean          | 198          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1464         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062835924 |\n",
      "|    clip_fraction        | 0.0709       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.737       |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.1         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 395      |\n",
      "|    ep_rew_mean     | 204      |\n",
      "| time/              |          |\n",
      "|    fps             | 1871     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 335872   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 416          |\n",
      "|    ep_rew_mean          | 204          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1321         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036009597 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.712       |\n",
      "|    explained_variance   | 0.773        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 97           |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 418      |\n",
      "|    ep_rew_mean     | 206      |\n",
      "| time/              |          |\n",
      "|    fps             | 1745     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 352256   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 419          |\n",
      "|    ep_rew_mean          | 205          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1376         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050563463 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.714       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.5         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    value_loss           | 58.3         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 423      |\n",
      "|    ep_rew_mean     | 198      |\n",
      "| time/              |          |\n",
      "|    fps             | 2064     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 436          |\n",
      "|    ep_rew_mean          | 193          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1292         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050046835 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.7         |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.3         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 411      |\n",
      "|    ep_rew_mean     | 195      |\n",
      "| time/              |          |\n",
      "|    fps             | 2088     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 385024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 417         |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005545954 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 441      |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    fps             | 1420     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 452         |\n",
      "|    ep_rew_mean          | 190         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1251        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007085327 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    value_loss           | 48.8        |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 452      |\n",
      "|    ep_rew_mean     | 198      |\n",
      "| time/              |          |\n",
      "|    fps             | 1619     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 417792   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 457          |\n",
      "|    ep_rew_mean          | 199          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1280         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040255208 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.676       |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 56.1         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.000211    |\n",
      "|    value_loss           | 46.8         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 463      |\n",
      "|    ep_rew_mean     | 205      |\n",
      "| time/              |          |\n",
      "|    fps             | 1901     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 434176   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 419         |\n",
      "|    ep_rew_mean          | 215         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1325        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005728863 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 421      |\n",
      "|    ep_rew_mean     | 217      |\n",
      "| time/              |          |\n",
      "|    fps             | 1943     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 427         |\n",
      "|    ep_rew_mean          | 219         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005740186 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.88        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 46.1        |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 413      |\n",
      "|    ep_rew_mean     | 222      |\n",
      "| time/              |          |\n",
      "|    fps             | 2047     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 466944   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 415          |\n",
      "|    ep_rew_mean          | 218          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1371         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058016824 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.743       |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 38.4         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 418      |\n",
      "|    ep_rew_mean     | 221      |\n",
      "| time/              |          |\n",
      "|    fps             | 1971     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 483328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 429         |\n",
      "|    ep_rew_mean          | 222         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1403        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006557201 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os\n",
    "\n",
    "models_dir = \"models/PPO\"\n",
    "logdir = \"logs\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "    \n",
    "# Create and wrap the environment\n",
    "env = make_vec_env(\"LunarLander-v3\", n_envs=4)  # Parallel environments for faster training\n",
    "\n",
    "# Define the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=logdir)\n",
    "\n",
    "# Train the agent\n",
    "TIMESTEPS = 10000\n",
    "iters = 0\n",
    "for i in range(30):\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=\"PPO\")\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*i}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 :Test and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Load the trained model\n",
    "models_dir = \"models/PPO\"\n",
    "model_path = f\"{models_dir}/290000\"\n",
    "model = PPO.load(model_path, env=env)\n",
    "\n",
    "# Create the environment for evaluation\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "# Run the trained model in the environment\n",
    "observation, info = env.reset()\n",
    "episode_over = False\n",
    "\n",
    "while not episode_over:\n",
    "    # Use the trained model to predict actions\n",
    "    action, _ = model.predict(observation, deterministic=True)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    episode_over = terminated or truncated\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
