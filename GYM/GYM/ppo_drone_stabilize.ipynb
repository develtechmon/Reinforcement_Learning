{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DroneRecoveryEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human']}\n",
    "    \n",
    "    def __init__(self, render_mode=None):\n",
    "        super(DroneRecoveryEnv, self).__init__()\n",
    "\n",
    "        # Canvas size\n",
    "        self.width = 600\n",
    "        self.height = 400\n",
    "\n",
    "        # Drone parameters\n",
    "        self.drone_pos = np.array([self.width / 2, self.height / 2], dtype=np.float32)\n",
    "        self.drone_vel = np.array([0.0, 0.0], dtype=np.float32)\n",
    "        self.max_speed = 5.0\n",
    "\n",
    "        # Balloon parameters\n",
    "        self.balloon_pos = np.array([np.random.uniform(0, self.width), 0], dtype=np.float32)  # Starts at top\n",
    "        self.balloon_vel = np.array([0, np.random.uniform(2, 5)], dtype=np.float32)  # Moves downward\n",
    "\n",
    "        # Recovery parameters\n",
    "        self.is_recovering = False\n",
    "        self.recovery_steps = 0\n",
    "        self.max_recovery_steps = 30  # Steps needed to stabilize\n",
    "\n",
    "        # Action space: Thrust for left and right\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n",
    "\n",
    "        # Observation space: [Drone position, Drone velocity, Balloon position]\n",
    "        low_obs = np.array([0, 0, -self.max_speed, -self.max_speed, 0, 0], dtype=np.float32)\n",
    "        high_obs = np.array([self.width, self.height, self.max_speed, self.max_speed, self.width, self.height], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=low_obs, high=high_obs, dtype=np.float32)\n",
    "\n",
    "        # Rendering\n",
    "        self.render_mode = render_mode\n",
    "        if self.render_mode == 'human':\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        # Episode parameters\n",
    "        self.max_steps = 500\n",
    "        self.current_step = 0\n",
    "        self.score = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Reset drone position and velocity\n",
    "        self.drone_pos = np.array([self.width / 2, self.height / 2], dtype=np.float32)\n",
    "        self.drone_vel = np.array([0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "        # Reset balloon position\n",
    "        self.balloon_pos = np.array([np.random.uniform(0, self.width), 0], dtype=np.float32)\n",
    "        self.balloon_vel = np.array([0, np.random.uniform(2, 5)], dtype=np.float32)\n",
    "\n",
    "        self.is_recovering = False\n",
    "        self.recovery_steps = 0\n",
    "        self.current_step = 0\n",
    "        self.score = 0\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if not self.is_recovering:\n",
    "            # Ensure action is a 1D array\n",
    "            action = np.array(action).flatten()\n",
    "            \n",
    "            # Apply horizontal thrust to the drone\n",
    "            left, right = action[0], action[1]\n",
    "            thrust = right - left  # Horizontal movement\n",
    "            self.drone_vel[0] += thrust\n",
    "\n",
    "            # Add random horizontal drift to simulate natural movement\n",
    "            random_drift = np.random.uniform(-0.5, 0.5)\n",
    "            self.drone_vel[0] += random_drift\n",
    "\n",
    "            # Limit horizontal speed\n",
    "            if abs(self.drone_vel[0]) > self.max_speed:\n",
    "                self.drone_vel[0] = np.sign(self.drone_vel[0]) * self.max_speed\n",
    "\n",
    "            # Update horizontal position only (Y position remains fixed)\n",
    "            self.drone_pos[0] += self.drone_vel[0]\n",
    "            self.drone_pos[0] = np.clip(self.drone_pos[0], 0, self.width)\n",
    "        else:\n",
    "            # Recovery logic: Gradually stabilize the drone\n",
    "            self.recovery_steps += 1\n",
    "            self.drone_vel = self.drone_vel * 0.9  # Dampen velocity\n",
    "            if self.recovery_steps >= self.max_recovery_steps:\n",
    "                self.is_recovering = False\n",
    "                self.recovery_steps = 0\n",
    "                self.drone_vel = np.array([0.0, 0.0], dtype=np.float32)\n",
    "\n",
    "        # Update balloon position\n",
    "        self.balloon_pos += self.balloon_vel\n",
    "        if self.balloon_pos[1] > self.height:\n",
    "            self.balloon_pos = np.array([np.random.uniform(0, self.width), 0], dtype=np.float32)\n",
    "            self.balloon_vel = np.array([0, np.random.uniform(2, 5)], dtype=np.float32)\n",
    "\n",
    "        # Check for collision\n",
    "        distance = np.linalg.norm(self.drone_pos - self.balloon_pos)\n",
    "        if distance < 10.0:  # Collision detected\n",
    "            self.is_recovering = True\n",
    "            self.score -= 1  # Penalty for being hit\n",
    "\n",
    "        # Reward logic\n",
    "        reward = 1.0 if not self.is_recovering else -1.0  # Reward for stability, penalty for recovery\n",
    "\n",
    "        # Increment step count\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_steps\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = {\"score\": self.score}\n",
    "\n",
    "        if self.render_mode == 'human':\n",
    "            self.render()\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode != 'human':\n",
    "            return\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "\n",
    "        self.screen.fill((255, 255, 255))  # White background\n",
    "\n",
    "        # Draw balloon\n",
    "        pygame.draw.circle(self.screen, (255, 0, 0), self.balloon_pos.astype(int), 10)  # Red balloon\n",
    "\n",
    "        # Draw drone\n",
    "        drone_color = (0, 0, 255) if not self.is_recovering else (255, 165, 0)  # Blue if stable, orange if recovering\n",
    "        pygame.draw.rect(self.screen, drone_color, (*self.drone_pos - 10, 20, 20))  # Drone as a square\n",
    "\n",
    "        # Display score\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        score_label = font.render(f\"Score: {self.score}\", True, (0, 0, 0))\n",
    "        self.screen.blit(score_label, (10, 10))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(30)\n",
    "\n",
    "    def close(self):\n",
    "        if self.render_mode == 'human':\n",
    "            pygame.quit()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # Observation includes drone position, velocity, and balloon position\n",
    "        return np.concatenate((self.drone_pos, self.drone_vel, self.balloon_pos)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Create vectorized environment for parallel training\n",
    "env = make_vec_env(lambda: DroneRecoveryEnv(), n_envs=4)\n",
    "\n",
    "# Define the PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=800000)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_drone_stabilize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp\\ipykernel_16524\\4049468141.py:143: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  pygame.draw.rect(self.screen, drone_color, (*self.drone_pos - 10, 20, 20))  # Drone as a square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: 900.0\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = PPO.load(\"ppo_drone_stabilize\")\n",
    "\n",
    "# Create the environment with rendering enabled\n",
    "env = DroneRecoveryEnv(render_mode='human')\n",
    "\n",
    "# Reset the environment\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Simulate for 30 seconds (30 FPS)\n",
    "num_steps = 30 * 30  # 30 seconds * 30 FPS = 900 steps\n",
    "total_reward = 0.0\n",
    "\n",
    "for _ in range(num_steps):\n",
    "    # Get action from the model\n",
    "    action, _ = model.predict(observation, deterministic=True)\n",
    "    \n",
    "    # Step the environment\n",
    "    observation, reward, done, _, info = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(f\"Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp\\ipykernel_16524\\4049468141.py:143: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  pygame.draw.rect(self.screen, drone_color, (*self.drone_pos - 10, 20, 20))  # Drone as a square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: 900.0\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Load the trained model\n",
    "model = PPO.load(\"ppo_drone_stabilize\")\n",
    "\n",
    "# Create the environment with rendering enabled\n",
    "env = DroneRecoveryEnv(render_mode='human')\n",
    "\n",
    "# Reset the environment\n",
    "observation, info = env.reset()\n",
    "\n",
    "#num_steps = 300  # Simulate for 300 steps (10 seconds at 30 FPS)\n",
    "num_steps = 30 * 30  # 30 seconds * 30 FPS = 900 steps\n",
    "\n",
    "done = False\n",
    "total_reward = 0.0\n",
    "\n",
    "#while not done:\n",
    "for _ in range(num_steps):\n",
    "\n",
    "    # Get action from the model\n",
    "    action, _ = model.predict(observation, deterministic=True)\n",
    "    \n",
    "    # Step the environment\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "\n",
    "print(f\"Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DroneHoverEnv(render_mode=\"human\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "for step in range(500):  # Run for 500 steps\n",
    "    action = np.random.uniform(-1, 1, size=(2,))  # Random left and right thrust actions\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    print(f\"Step: {step}, Reward: {reward}, Score: {info['score']}\")\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
