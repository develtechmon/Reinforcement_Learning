{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "import pygame\n",
    "\n",
    "# Define a custom environment for a line-following car\n",
    "class LineFollowingCarEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        # Initialize the base class for a custom Gymnasium environment\n",
    "        super(LineFollowingCarEnv, self).__init__()\n",
    "\n",
    "        # Define the observation space\n",
    "        # Observation includes:\n",
    "        # - position_error: how far the car is from the line (-10 to 10)\n",
    "        # - angle_to_line: the car's angle relative to the line (-π to π)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([-10.0, -np.pi]),  # Minimum values\n",
    "            high=np.array([10.0, np.pi]),  # Maximum values\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Define the action space\n",
    "        # Actions are the PID gains [Kp, Ki, Kd] (Proportional, Integral, Derivative)\n",
    "        # These values range from 0 to 10\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([0.0, 0.0, 0.0]),  # Minimum gains\n",
    "            high=np.array([10.0, 10.0, 10.0]),  # Maximum gains\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Initialize Pygame for visualization\n",
    "        pygame.init()\n",
    "        self.width, self.height = 800, 400  # Window dimensions\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        pygame.display.set_caption(\"Line Following Car\")  # Title of the Pygame window\n",
    "        self.clock = pygame.time.Clock()  # Control the frame rate\n",
    "\n",
    "        # Define colors for visualization\n",
    "        self.white = (255, 255, 255)  # Background color\n",
    "        self.black = (0, 0, 0)        # Text color (unused here)\n",
    "        self.red = (255, 0, 0)        # Line color\n",
    "        self.blue = (0, 0, 255)       # Car color\n",
    "\n",
    "        # Define car properties\n",
    "        self.car_pos_x = self.width // 2  # Car's horizontal position\n",
    "        self.car_pos_y = self.height // 2  # Car's vertical position\n",
    "        self.car_width, self.car_height = 40, 20  # Car dimensions\n",
    "\n",
    "        # Reset the environment to initialize all variables\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Set the seed for reproducibility (optional)\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # Initialize the car's state\n",
    "        self.position_error = np.random.uniform(-2.0, 2.0)  # Random initial offset from the line\n",
    "        self.angle_to_line = np.random.uniform(-np.pi / 4, np.pi / 4)  # Random initial angle\n",
    "        self.time_step = 0  # Reset the time step counter\n",
    "        self.total_error = 0.0  # Reset the accumulated error for the integral term\n",
    "\n",
    "        # Start the car at the left edge of the window\n",
    "        self.car_pos_x = 0  \n",
    "\n",
    "        # Return the initial observation (state) and an empty info dictionary\n",
    "        return np.array([self.position_error, self.angle_to_line], dtype=np.float32), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Unpack the PID gains (actions taken by the agent)\n",
    "        Kp, Ki, Kd = action\n",
    "\n",
    "        # Compute the PID correction\n",
    "        correction = (\n",
    "            Kp * self.position_error +                     # Proportional term\n",
    "            Ki * self.total_error +                       # Integral term (sum of past errors)\n",
    "            Kd * (self.position_error - getattr(self, \"prev_position_error\", 0))  # Derivative term\n",
    "        )\n",
    "\n",
    "        # Update the car's state based on the correction\n",
    "        self.prev_position_error = self.position_error  # Store the previous position error\n",
    "        self.position_error -= correction * np.cos(self.angle_to_line)  # Adjust position error\n",
    "        self.angle_to_line -= correction * 0.1  # Adjust the angle slightly (simplified physics)\n",
    "\n",
    "        # Move the car forward (right) and adjust its vertical position based on the error\n",
    "        self.car_pos_x += 5  # Move horizontally by 5 units per step\n",
    "        self.car_pos_y = self.height // 2 + int(self.position_error * 20)  # Adjust vertical position\n",
    "\n",
    "        # Clamp the position error and angle to their defined limits\n",
    "        self.position_error = np.clip(self.position_error, -10, 10)\n",
    "        self.angle_to_line = np.clip(self.angle_to_line, -np.pi, np.pi)\n",
    "\n",
    "        # Compute the reward\n",
    "        # Reward is higher (closer to 0) when the car stays near the line with minimal corrections\n",
    "        reward = -abs(self.position_error) - 0.01 * abs(correction)\n",
    "\n",
    "        # Accumulate the position error for the integral term\n",
    "        self.total_error += self.position_error\n",
    "\n",
    "        # Determine if the episode is done\n",
    "        # - Episode ends if the car runs for 200 timesteps or moves too far off the line\n",
    "        self.time_step += 1\n",
    "        done = self.time_step >= 200 or abs(self.position_error) > 10\n",
    "\n",
    "        # Return the updated state, reward, and whether the episode is done\n",
    "        return (\n",
    "            np.array([self.position_error, self.angle_to_line], dtype=np.float32),\n",
    "            reward,\n",
    "            done,\n",
    "            False,\n",
    "            {}\n",
    "        )\n",
    "            \n",
    "    def render(self):\n",
    "        # Handle Pygame events (e.g., close the window)\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:  # If the close button is clicked\n",
    "                self.close()\n",
    "                exit()\n",
    "\n",
    "        # Clear the screen with a white background\n",
    "        self.screen.fill(self.white)\n",
    "\n",
    "        # Draw the red line (the target line the car should follow)\n",
    "        pygame.draw.line(\n",
    "            self.screen,\n",
    "            self.red,\n",
    "            (0, self.height // 2),  # Start point of the line\n",
    "            (self.width, self.height // 2),  # End point of the line\n",
    "            2,  # Thickness of the line\n",
    "        )\n",
    "\n",
    "        # Draw the car as a blue rectangle\n",
    "        pygame.draw.rect(\n",
    "            self.screen,\n",
    "            self.blue,\n",
    "            (self.car_pos_x - self.car_width // 2, self.car_pos_y - self.car_height // 2, self.car_width, self.car_height),\n",
    "        )\n",
    "\n",
    "        # Update the display to reflect the changes\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Limit the frame rate to 30 FPS\n",
    "        self.clock.tick(30)\n",
    "\n",
    "    def close(self):\n",
    "        # Quit Pygame to clean up resources\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Create the environment\n",
    "env = LineFollowingCarEnv()\n",
    "\n",
    "# Train PPO\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=1000000)\n",
    "model.save(\"ppo_line_following_car\")\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -0.8375465851787444\n"
     ]
    }
   ],
   "source": [
    "env = LineFollowingCarEnv()\n",
    "model = PPO.load(\"ppo_pid_car\")  # Load the trained model\n",
    "\n",
    "obs, _ = env.reset()\n",
    "done, truncated = False, False\n",
    "total_reward = 0\n",
    "\n",
    "while not (done or truncated):\n",
    "    action, _ = model.predict(obs, deterministic=True)  # Predict action using PPO\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "    env.render()  # Render the environment\n",
    "    \n",
    "print(f\"Total reward: {total_reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of Key Points\n",
    "\n",
    "    Observation Space:\n",
    "        The car senses its position error and angle relative to the line.\n",
    "\n",
    "    Action Space:\n",
    "        The agent controls PID gains to correct the car's position and angle.\n",
    "\n",
    "    Reward:\n",
    "        Reward is higher when the car stays close to the line and minimizes corrections.\n",
    "\n",
    "    Render:\n",
    "        The Pygame window visualizes the car’s movement and its relationship to the line.\n",
    "\n",
    "    Termination:\n",
    "        The episode ends when the car goes too far off the line or after 200 timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
